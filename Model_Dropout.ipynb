{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5305de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54bab207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dropout\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "def data_preprocessing(df):\n",
    "    \n",
    "    col_to_keep = ['death', 'age', 'blood', 'reflex', 'bloodchem1', 'bloodchem2', 'psych1', 'glucose']\n",
    "    df = df[col_to_keep]\n",
    "\n",
    "    df.replace('', 0, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "    \n",
    "def split_feature_label(df):\n",
    "    y = df['death']\n",
    "    X = df.drop(columns=['death'])\n",
    "    return y, X\n",
    "    # print(X)\n",
    "    # print(y)\n",
    "\n",
    "    # death_0 = y.tolist().count(0)\n",
    "    # death_1 = y.tolist().count(1)\n",
    "    # percent_death_0 = 100 * death_0 / (death_0 + death_1)\n",
    "    # percent_death_1 = 100 * death_1 / (death_0 + death_1)\n",
    "    # print(f'Survived: {death_0}, or {percent_death_0:.2f}%')\n",
    "    # print(f'Died: {death_1}, or {percent_death_1:.2f}%')\n",
    "\n",
    "def standardize(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_numeric = scaler.fit_transform(X.select_dtypes(include=['float64']))\n",
    "    X[X.select_dtypes(include=['float64']).columns] = X_numeric\n",
    "    return X\n",
    "\n",
    "def train_model2(X, y):\n",
    "    # Split data into training and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Define the neural network model\n",
    "    model2 = keras.Sequential([\n",
    "        layers.Input(shape=(X_train.shape[1],)),  # Input layer\n",
    "        layers.Dense(512, activation='relu',kernel_regularizer=regularizers.L1(0.01)), \n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu',kernel_regularizer=regularizers.L1(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu',kernel_regularizer=regularizers.L1(0.01)),  # Hidden layer with 128 neurons and ReLU activation\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu' ,kernel_regularizer=regularizers.L1(0.01)),      # Another hidden layer with 64 neurons and ReLU activation\n",
    "        layers.Dense(1, activation='sigmoid')     # Output layer with sigmoid activation for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model2.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model2.evaluate(X_test, y_test)\n",
    "\n",
    "    \n",
    "    model2.save('example2.h5')\n",
    "    \n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "    # Optionally, you can plot training history to visualize model performance\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "#     plt.plot(history.history['accuracy'], label='accuracy')\n",
    "#     plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.show()\n",
    "\n",
    "def run_model_dropout(cleaned_data):\n",
    "    y, X = split_feature_label(cleaned_data)\n",
    "    X = standardize(X)\n",
    "    train_model2(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa53ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7058, 44) (7058, 57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from preproc import Dataset\n",
    "df = pd.read_csv(\"./TD_HOSPITAL_TRAIN.csv\")\n",
    "cleaned_data = Dataset(df).data\n",
    "print(df.shape,cleaned_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bd0061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 20:25:37.593371: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 2ms/step - loss: 24.9576 - accuracy: 0.6646 - val_loss: 1.1401 - val_accuracy: 0.6643\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.9075 - accuracy: 0.6727 - val_loss: 0.8848 - val_accuracy: 0.6643\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8786 - accuracy: 0.6727 - val_loss: 0.8849 - val_accuracy: 0.6643\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8795 - accuracy: 0.6727 - val_loss: 0.8854 - val_accuracy: 0.6643\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8794 - accuracy: 0.6727 - val_loss: 0.8857 - val_accuracy: 0.6643\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8795 - accuracy: 0.6727 - val_loss: 0.8861 - val_accuracy: 0.6643\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8860 - val_accuracy: 0.6643\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8862 - val_accuracy: 0.6643\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8845 - val_accuracy: 0.6643\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8854 - val_accuracy: 0.6643\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8853 - val_accuracy: 0.6643\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8846 - val_accuracy: 0.6643\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8874 - val_accuracy: 0.6643\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8859 - val_accuracy: 0.6643\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8854 - val_accuracy: 0.6643\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8849 - val_accuracy: 0.6643\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8868 - val_accuracy: 0.6643\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8858 - val_accuracy: 0.6643\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8862 - val_accuracy: 0.6643\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8855 - val_accuracy: 0.6643\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8799 - accuracy: 0.6727 - val_loss: 0.8848 - val_accuracy: 0.6643\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8854 - val_accuracy: 0.6643\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8855 - val_accuracy: 0.6643\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8854 - val_accuracy: 0.6643\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8799 - accuracy: 0.6727 - val_loss: 0.8855 - val_accuracy: 0.6643\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8800 - accuracy: 0.6727 - val_loss: 0.8857 - val_accuracy: 0.6643\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8861 - val_accuracy: 0.6643\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8854 - val_accuracy: 0.6643\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8849 - val_accuracy: 0.6643\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8862 - val_accuracy: 0.6643\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8851 - val_accuracy: 0.6643\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8854 - val_accuracy: 0.6643\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8852 - val_accuracy: 0.6643\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8859 - val_accuracy: 0.6643\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8850 - val_accuracy: 0.6643\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8856 - val_accuracy: 0.6643\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8866 - val_accuracy: 0.6643\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8863 - val_accuracy: 0.6643\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8853 - val_accuracy: 0.6643\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8853 - val_accuracy: 0.6643\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8854 - val_accuracy: 0.6643\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6727 - val_loss: 0.8864 - val_accuracy: 0.6643\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8852 - val_accuracy: 0.6643\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8855 - val_accuracy: 0.6643\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8853 - val_accuracy: 0.6643\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8850 - val_accuracy: 0.6643\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8795 - accuracy: 0.6727 - val_loss: 0.8858 - val_accuracy: 0.6643\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.6727 - val_loss: 0.8853 - val_accuracy: 0.6643\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6727 - val_loss: 0.8854 - val_accuracy: 0.6643\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.8799 - accuracy: 0.6727 - val_loss: 0.8860 - val_accuracy: 0.6643\n",
      "18/18 [==============================] - 0s 610us/step - loss: 0.8601 - accuracy: 0.6991\n",
      "Test accuracy: 0.6991150379180908\n"
     ]
    }
   ],
   "source": [
    "run_model_dropout(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1fc70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
