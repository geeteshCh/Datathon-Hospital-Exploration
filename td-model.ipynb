{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d5132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6729c1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7058, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeknown</th>\n",
       "      <th>cost</th>\n",
       "      <th>reflex</th>\n",
       "      <th>sex</th>\n",
       "      <th>blood</th>\n",
       "      <th>bloodchem1</th>\n",
       "      <th>bloodchem2</th>\n",
       "      <th>temperature</th>\n",
       "      <th>race</th>\n",
       "      <th>heart</th>\n",
       "      <th>...</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>income</th>\n",
       "      <th>extraprimary</th>\n",
       "      <th>bloodchem6</th>\n",
       "      <th>education</th>\n",
       "      <th>psych5</th>\n",
       "      <th>psych6</th>\n",
       "      <th>information</th>\n",
       "      <th>cancer</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3008.38867</td>\n",
       "      <td>11.228005</td>\n",
       "      <td>male</td>\n",
       "      <td>20.699219</td>\n",
       "      <td>2.199707</td>\n",
       "      <td>1.299805</td>\n",
       "      <td>35.59375</td>\n",
       "      <td>white</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>167.5000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>467.0</td>\n",
       "      <td>23585.89060</td>\n",
       "      <td>9.714861</td>\n",
       "      <td>M</td>\n",
       "      <td>9.398438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>white</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&gt;$50k</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>480.0000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>metastatic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>533.0</td>\n",
       "      <td>4046.45898</td>\n",
       "      <td>11.353296</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.296875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.599854</td>\n",
       "      <td>38.19531</td>\n",
       "      <td>white</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>177.1250</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.269058</td>\n",
       "      <td>female</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>37.59375</td>\n",
       "      <td>white</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.839</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1605.0</td>\n",
       "      <td>6457.70703</td>\n",
       "      <td>8.655387</td>\n",
       "      <td>female</td>\n",
       "      <td>15.099609</td>\n",
       "      <td>4.399414</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>35.69531</td>\n",
       "      <td>white</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>233.3125</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.037731</td>\n",
       "      <td>female</td>\n",
       "      <td>15.298828</td>\n",
       "      <td>3.199707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.59375</td>\n",
       "      <td>white</td>\n",
       "      <td>118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>167.5000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>713.0</td>\n",
       "      <td>1664.37988</td>\n",
       "      <td>12.431059</td>\n",
       "      <td>Male</td>\n",
       "      <td>13.798828</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>276.1875</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>metastatic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1475.0</td>\n",
       "      <td>2440.39844</td>\n",
       "      <td>9.355022</td>\n",
       "      <td>female</td>\n",
       "      <td>3.199707</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>36.50000</td>\n",
       "      <td>white</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>165.6875</td>\n",
       "      <td>54.865518</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>metastatic</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17679.00000</td>\n",
       "      <td>10.720581</td>\n",
       "      <td>male</td>\n",
       "      <td>0.199982</td>\n",
       "      <td>2.299805</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>39.39844</td>\n",
       "      <td>black</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$25-$50k</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.511660</td>\n",
       "      <td>female</td>\n",
       "      <td>9.699219</td>\n",
       "      <td>3.299805</td>\n",
       "      <td>1.199951</td>\n",
       "      <td>36.19531</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>200.0000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>24.666656</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timeknown         cost     reflex     sex      blood  bloodchem1  \\\n",
       "0        4.0   3008.38867  11.228005    male  20.699219    2.199707   \n",
       "1      467.0  23585.89060   9.714861       M   9.398438         NaN   \n",
       "2      533.0   4046.45898  11.353296    Male  19.296875         NaN   \n",
       "3       68.0          NaN   9.269058  female   7.500000    2.500000   \n",
       "4     1605.0   6457.70703   8.655387  female  15.099609    4.399414   \n",
       "5       15.0          NaN   9.037731  female  15.298828    3.199707   \n",
       "6      713.0   1664.37988  12.431059    Male  13.798828    4.000000   \n",
       "7     1475.0   2440.39844   9.355022  female   3.199707    2.000000   \n",
       "8        5.0  17679.00000  10.720581    male   0.199982    2.299805   \n",
       "9       20.0          NaN  10.511660  female   9.699219    3.299805   \n",
       "\n",
       "   bloodchem2  temperature   race  heart  ...  diabetes      income  \\\n",
       "0    1.299805     35.59375  white  103.0  ...       0.0    $11-$25k   \n",
       "1    0.699951     39.00000  white   50.0  ...       0.0       >$50k   \n",
       "2    1.599854     38.19531  white   50.0  ...       1.0  under $11k   \n",
       "3    0.599976     37.59375  white   80.0  ...       0.0    $11-$25k   \n",
       "4    0.699951     35.69531  white  114.0  ...       0.0  under $11k   \n",
       "5    1.000000     36.59375  white  118.0  ...       0.0         NaN   \n",
       "6    0.899902     36.00000  white   71.0  ...       0.0  under $11k   \n",
       "7    0.899902     36.50000  white   62.0  ...       0.0  under $11k   \n",
       "8    0.599976     39.39844  black  115.0  ...       0.0    $25-$50k   \n",
       "9    1.199951     36.19531  white   70.0  ...       1.0  under $11k   \n",
       "\n",
       "         extraprimary  bloodchem6  education     psych5  psych6  information  \\\n",
       "0  COPD/CHF/Cirrhosis    167.5000  20.000000  30.000000   2.000          0.0   \n",
       "1              Cancer    480.0000  16.000000  11.500000   1.000         10.0   \n",
       "2            ARF/MOSF    177.1250   5.000000  18.000000   0.000          5.0   \n",
       "3  COPD/CHF/Cirrhosis         NaN  12.000000   7.000000   1.839         12.0   \n",
       "4  COPD/CHF/Cirrhosis    233.3125   2.000000   7.000000   6.000         12.0   \n",
       "5            ARF/MOSF    167.5000  12.000000  47.000000   0.000         13.0   \n",
       "6              Cancer    276.1875   8.000000   4.000000   0.000          3.0   \n",
       "7            ARF/MOSF    165.6875  54.865518  48.000000   0.000          8.0   \n",
       "8            ARF/MOSF    120.0000  12.000000  52.000000   2.000          5.0   \n",
       "9            ARF/MOSF    200.0000  12.000000  24.666656   6.000          2.0   \n",
       "\n",
       "       cancer  death  \n",
       "0          no    1.0  \n",
       "1  metastatic    1.0  \n",
       "2         yes    0.0  \n",
       "3          no    1.0  \n",
       "4          no    0.0  \n",
       "5          no    1.0  \n",
       "6  metastatic    1.0  \n",
       "7  metastatic    0.0  \n",
       "8         yes    1.0  \n",
       "9         yes    1.0  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./TD_HOSPITAL_TRAIN.csv\")\n",
    "print(df1.shape)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fba4417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7058,)\n",
      "(7058, 43)\n"
     ]
    }
   ],
   "source": [
    "y = df1['death']\n",
    "df1 = df1.drop(columns=['death'])\n",
    "print(y.shape)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34216546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7058, 43)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       timeknown         cost     reflex     sex      blood  bloodchem1  \\\n",
       "0           4.0   3008.38867  11.228005    male  20.699219    2.199707   \n",
       "1         467.0  23585.89060   9.714861       M   9.398438         NaN   \n",
       "2         533.0   4046.45898  11.353296    Male  19.296875         NaN   \n",
       "3          68.0          NaN   9.269058  female   7.500000    2.500000   \n",
       "4        1605.0   6457.70703   8.655387  female  15.099609    4.399414   \n",
       "...         ...          ...        ...     ...        ...         ...   \n",
       "7053      841.0  18825.79690  10.897551  female  15.099609         NaN   \n",
       "7054      258.0  68911.87500  10.325173    male   7.500000    3.199707   \n",
       "7055     1325.0  15684.64840   9.838906  female  35.000000    2.799805   \n",
       "7056        4.0          NaN   9.141439       1  18.199219    3.000000   \n",
       "7057       14.0   5133.14844  11.006892  female  12.599609    2.299805   \n",
       "\n",
       "      bloodchem2  temperature   race  heart  ...   urine  diabetes  \\\n",
       "0       1.299805     35.59375  white  103.0  ...  5360.0       0.0   \n",
       "1       0.699951     39.00000  white   50.0  ...  2570.0       0.0   \n",
       "2       1.599854     38.19531  white   50.0  ...  1690.0       1.0   \n",
       "3       0.599976     37.59375  white   80.0  ...     NaN       0.0   \n",
       "4       0.699951     35.69531  white  114.0  ...     NaN       0.0   \n",
       "...          ...          ...    ...    ...  ...     ...       ...   \n",
       "7053    0.899902     38.00000  black  150.0  ...  1830.0       0.0   \n",
       "7054    0.899902     37.59375  white  112.0  ...  1130.0       0.0   \n",
       "7055    0.599976     36.59375  white  126.0  ...     NaN       0.0   \n",
       "7056    0.899902     39.29688  white  132.0  ...     NaN       0.0   \n",
       "7057    0.699951     38.50000  white  114.0  ...  1840.0       0.0   \n",
       "\n",
       "          income        extraprimary  bloodchem6  education  psych5    psych6  \\\n",
       "0       $11-$25k  COPD/CHF/Cirrhosis    167.5000       20.0    30.0  2.000000   \n",
       "1          >$50k              Cancer    480.0000       16.0    11.5  1.000000   \n",
       "2     under $11k            ARF/MOSF    177.1250        5.0    18.0  0.000000   \n",
       "3       $11-$25k  COPD/CHF/Cirrhosis         NaN       12.0     7.0  1.839000   \n",
       "4     under $11k  COPD/CHF/Cirrhosis    233.3125        2.0     7.0  6.000000   \n",
       "...          ...                 ...         ...        ...     ...       ...   \n",
       "7053    $25-$50k                Coma    371.3750       17.0    17.0  5.000000   \n",
       "7054       >$50k            ARF/MOSF    122.4375       20.0    24.5  0.000000   \n",
       "7055  under $11k  COPD/CHF/Cirrhosis    240.0000        NaN    32.5  0.000000   \n",
       "7056         NaN                Coma    228.0000        NaN    32.0  2.317871   \n",
       "7057  under $11k  COPD/CHF/Cirrhosis         NaN       12.0     8.0  5.000000   \n",
       "\n",
       "      information      cancer  \n",
       "0             0.0          no  \n",
       "1            10.0  metastatic  \n",
       "2             5.0         yes  \n",
       "3            12.0          no  \n",
       "4            12.0          no  \n",
       "...           ...         ...  \n",
       "7053         11.0          no  \n",
       "7054         48.0  metastatic  \n",
       "7055         11.0          no  \n",
       "7056          3.0         yes  \n",
       "7057          7.0          no  \n",
       "\n",
       "[7058 rows x 43 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(df1.shape)\n",
    "df1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f75fcebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = replace_missing_with_knn(df, 'psych4', n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83885d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, data: pd.DataFrame) -> None:\n",
    "        # drop columns\n",
    "        self.data = data.copy()\n",
    "\n",
    "        # drop columns\n",
    "        self.data = self.data.drop('pdeath',axis=1)\n",
    "        self.data = self.data.drop('psych4',axis=1)\n",
    "        self.data = self.data.drop('glucose',axis=1)\n",
    "        self.data = self.data.drop('bloodchem4', axis=1)\n",
    "        self.data = self.data.drop('urine',axis =1)\n",
    "        self.data = self.data.drop('income',axis =1)\n",
    "\n",
    "        # clean data\n",
    "        self.data = data.apply(self.clean, axis=1)\n",
    "\n",
    "        # replace missing data\n",
    "        self.clean_fill_mean('psych2')\n",
    "        self.clean_fill_mean('bloodchem3')\n",
    "        self.replace_missing_with_knn('totalcost', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('confidence', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('bloodchem1', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('bloodchem2', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('blood', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('cost', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('sleep', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('bloodchem5', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('administratorcost')\n",
    "        self.replace_missing_with_knn('diabetes')\n",
    "        self.replace_missing_with_knn('bloodchem6')\n",
    "        self.replace_missing_with_knn('education')\n",
    "        self.replace_missing_with_knn('psych5')\n",
    "        self.replace_missing_with_knn('psych6')\n",
    "        self.replace_missing_with_knn('information')\n",
    "\n",
    "        # one hot encode the data\n",
    "        self.data = self.one_hot_encode_feature('cancer')\n",
    "        # self.data = self.one_hot_encode_feature('extraprimary')\n",
    "\n",
    "\n",
    "    \n",
    "    def clean(self, row):\n",
    "        row.sex = self.cleanSex(row.sex)\n",
    "        row.race = self.cleanRace(row.race)\n",
    "        row.cost = self.cleanCost(row.cost)\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    # preproc for cost\n",
    "    def cleanCost(self, val: float):\n",
    "        if pd.isna(val) or val < 0:\n",
    "            return np.nan\n",
    "        \n",
    "        return val\n",
    "\n",
    "\n",
    "    # preproc logic for cleaning sex\n",
    "    def cleanSex(self, val):\n",
    "        val = val.lower()\n",
    "        # 1: male\n",
    "        if val in ['male', 'm', '1']:\n",
    "            return 1\n",
    "        # 0: female\n",
    "        return 0\n",
    "\n",
    "    # preproc logic for race\n",
    "    def cleanRace(self, val):\n",
    "        # unique values: ['white', 'black', 'hispanic', 'other', nan, 'asian']\n",
    "        WHITE = 0\n",
    "        BLACK = 1\n",
    "        HISPANIC = 2\n",
    "        OTHER = 3\n",
    "        ASIAN = 4\n",
    "\n",
    "        if(pd.isna(val)):\n",
    "            return OTHER\n",
    "        \n",
    "        val = val.lower()\n",
    "\n",
    "        if val == 'white':\n",
    "            return WHITE\n",
    "        elif val == 'black':\n",
    "            return BLACK\n",
    "        elif val == 'hispanic':\n",
    "            return HISPANIC\n",
    "        elif val == 'other':\n",
    "            return OTHER\n",
    "        elif val == 'asian':\n",
    "            return ASIAN\n",
    "\n",
    "        print('not possible')\n",
    "        return -1\n",
    "    \n",
    "\n",
    "    def one_hot_encode_feature(self, feature_name):\n",
    "        \"\"\"\n",
    "        One-hot encodes a specified feature from a DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        - dataframe: The input DataFrame.\n",
    "        - feature_name: The name of the feature to be one-hot encoded.\n",
    "\n",
    "        Returns:\n",
    "        - one_hot_df: A DataFrame containing the one-hot encoded feature.\n",
    "        \"\"\"\n",
    "\n",
    "        # Select the specified feature from the DataFrame\n",
    "        feature_to_encode = self.data[feature_name]\n",
    "\n",
    "        # Reshape the feature to have a 2D shape, required by OneHotEncoder\n",
    "        feature_to_encode = feature_to_encode.values.reshape(-1, 1)\n",
    "\n",
    "        # Create an instance of the OneHotEncoder\n",
    "        encoder = OneHotEncoder(sparse=False)  # You can set sparse=True if you want a sparse matrix\n",
    "\n",
    "        # Fit the encoder to the feature data\n",
    "        encoder.fit(feature_to_encode)\n",
    "\n",
    "        # Transform the feature data to one-hot encoded format\n",
    "        one_hot_encoded = encoder.transform(feature_to_encode)\n",
    "\n",
    "        # Convert the one-hot encoded data to a DataFrame for better visualization\n",
    "        one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out([feature_name]))\n",
    "        \n",
    "        \n",
    "        new_dataframe = self.data.drop(columns=[feature_name])  # Remove the target column\n",
    "        new_dataframe[one_hot_df.columns] = one_hot_df  # Add the source columns to the target DataFrame\n",
    "        \n",
    "        self.data = new_dataframe\n",
    "\n",
    "    # for glucose, psych2, \n",
    "    def clean_fill_mean(self, feature):\n",
    "        mean_value = self.data[feature].mean()\n",
    "        self.data[feature].fillna(mean_value, inplace=True)\n",
    "\n",
    "\n",
    "    # replacing the outliers after replacing missing values\n",
    "    def replace_outliers_with_mean(self, column_name, threshold=1.5):\n",
    "        # Calculate lower and upper bounds for outliers\n",
    "        Q1 = self.data[column_name].quantile(0.25)\n",
    "        Q3 = self.data[column_name].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "        # Identify outliers in the specified column\n",
    "        outliers = self.data[(self.data[column_name] < lower_bound) | (self.data[column_name] > upper_bound)]\n",
    "\n",
    "        # Replace outliers with the mean of the column\n",
    "        non_outliers_mean = self.data[([column_name] >= lower_bound) & (self.data[column_name] <= upper_bound)][column_name].mean()\n",
    "        self.data.loc[outliers.index, column_name] = non_outliers_mean\n",
    "\n",
    "\n",
    "    #replacing missing values with knn imputer\n",
    "    # for totalcost\n",
    "    def replace_missing_with_knn(self, column_name, n_neighbors=5):\n",
    "        # Create a copy of the DataFrame to avoid modifying the original data\n",
    "        df_imputed = self.data.copy()    \n",
    "        # Extract the column with missing values for imputation\n",
    "        column_to_impute = df_imputed[[column_name]]   \n",
    "        # Initialize KNNImputer with the desired number of neighbors\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)   \n",
    "        # Perform KNN imputation on the specified column\n",
    "        column_imputed = imputer.fit_transform(column_to_impute)   \n",
    "        # Replace the missing values in the original DataFrame with imputed values\n",
    "        df_imputed[column_name] = column_imputed\n",
    "        \n",
    "        self.data = df_imputed\n",
    "\n",
    "    \n",
    "    def fill_missing_categorical(self, categorical_feature):\n",
    "        \"\"\"\n",
    "        Fill missing values in a categorical feature with the most frequent category.\n",
    "\n",
    "        Parameters:\n",
    "        - df: DataFrame containing the data.\n",
    "        - categorical_feature: Name of the categorical feature/column with missing values.\n",
    "\n",
    "        Returns:\n",
    "        - Updated DataFrame with missing values filled in the specified feature.\n",
    "        \"\"\"\n",
    "        # Find the most frequent category in the specified feature\n",
    "        most_frequent_category = self.data[categorical_feature].mode()[0]\n",
    "        \n",
    "        # Fill missing values in the specified feature with the most frequent category\n",
    "        self.data[categorical_feature].fillna(most_frequent_category, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e91233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kajdkjfkafkjjfjkafkbkjabkfbkabfjkaf\n",
      "0               no\n",
      "1       metastatic\n",
      "2              yes\n",
      "3               no\n",
      "4               no\n",
      "           ...    \n",
      "7053            no\n",
      "7054    metastatic\n",
      "7055            no\n",
      "7056           yes\n",
      "7057            no\n",
      "Name: cancer, Length: 7058, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x21600ceb388>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Dataset(df1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc469a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-win_amd64.whl (1.9 kB)\n",
      "Collecting keras\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl (266.3 MB)\n",
      "     ------------------------------------ 266.3/266.3 MB 462.5 kB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.0-cp37-cp37m-win_amd64.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 731.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     ---------------------------------------- 6.0/6.0 MB 699.9 kB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (65.6.3)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-win_amd64.whl (896 kB)\n",
      "     -------------------------------------- 896.6/896.6 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     ---------------------------------------- 24.4/24.4 MB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "     -------------------------------------- 130.2/130.2 kB 3.9 MB/s eta 0:00:00\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp37-cp37m-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 3.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "     -------------------------------------- 233.6/233.6 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "     -------------------------------------- 182.3/182.3 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "     ---------------------------------------- 94.2/94.2 kB 5.2 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.3/181.3 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\vva\\.conda\\envs\\pytorch\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.11.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.9/83.9 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, keras, importlib-metadata, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.23.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.59.0 h5py-3.8.0 importlib-metadata-6.7.0 keras-2.11.0 libclang-16.0.6 markdown-3.4.4 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 werkzeug-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydocstyle 6.3.0 requires importlib-metadata<5.0.0,>=2.0.0; python_version < \"3.8\", but you have importlib-metadata 6.7.0 which is incompatible.\n",
      "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 6.7.0 which is incompatible.\n",
      "flake8 4.0.1 requires mccabe<0.7.0,>=0.6.0, but you have mccabe 0.7.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607dbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13bb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4e6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dd221db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_97952\\2861931483.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91039351",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_105936\\736866905.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = keras.Sequential([\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Input layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[1;31m# Hidden layer with 128 neurons and ReLU activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m      \u001b[1;31m# Another hidden layer with 64 neurons and ReLU activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# Output layer with sigmoid activation for binary classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train.shape[1],)),  # Input layer\n",
    "        layers.Dense(128, activation='relu'),     # Hidden layer with 128 neurons and ReLU activation\n",
    "        layers.Dense(64, activation='relu'),      # Another hidden layer with 64 neurons and ReLU activation\n",
    "        layers.Dense(1, activation='sigmoid')     # Output layer with sigmoid activation for binary classification\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37009d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7008849557522124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj Reddy Gurram\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\Manoj Reddy Gurram\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dropout\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def data_preprocessing(df):\n",
    "    \n",
    "    col_to_keep = ['death', 'age', 'blood', 'reflex', 'bloodchem1', 'bloodchem2', 'psych1', 'glucose']\n",
    "    df = df[col_to_keep]\n",
    "\n",
    "    df.replace('', 0, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "    \n",
    "def split_feature_label(df):\n",
    "    y = df['death']\n",
    "    X = df.drop(columns=['death'])\n",
    "    return y, X\n",
    "    # print(X)\n",
    "    # print(y)\n",
    "\n",
    "    # death_0 = y.tolist().count(0)\n",
    "    # death_1 = y.tolist().count(1)\n",
    "    # percent_death_0 = 100 * death_0 / (death_0 + death_1)\n",
    "    # percent_death_1 = 100 * death_1 / (death_0 + death_1)\n",
    "    # print(f'Survived: {death_0}, or {percent_death_0:.2f}%')\n",
    "    # print(f'Died: {death_1}, or {percent_death_1:.2f}%')\n",
    "\n",
    "def standardize(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_numeric = scaler.fit_transform(X.select_dtypes(include=['float64']))\n",
    "    X[X.select_dtypes(include=['float64']).columns] = X_numeric\n",
    "    return X\n",
    "\n",
    "def train_model(X, y):\n",
    "    # Split data into training and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Define the neural network model\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train.shape[1],)),  # Input layer\n",
    "        layers.Dense(512, activation='relu',kernel_regularizer=regularizers.L1(0.01)), \n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu',kernel_regularizer=regularizers.L1(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu',kernel_regularizer=regularizers.L1(0.01)),  # Hidden layer with 128 neurons and ReLU activation\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu' ,kernel_regularizer=regularizers.L1(0.01)),      # Another hidden layer with 64 neurons and ReLU activation\n",
    "        layers.Dense(1, activation='sigmoid')     # Output layer with sigmoid activation for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = Logistic_reg = LogisticRegression(random_state=42,max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred_proba = Logistic_reg.predict_proba(X_test)\n",
    "\n",
    "    # Calculate the log loss\n",
    "    test_loss = log_loss(y_test, y_pred_proba)\n",
    "    y_pred = Logistic_reg.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    model.save('example.h5')\n",
    "    \n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "    # Optionally, you can plot training history to visualize model performance\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "#     plt.plot(history.history['accuracy'], label='accuracy')\n",
    "#     plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"C:/Users/Manoj Reddy Gurram/Desktop/TDHospital/TDHospital/TD_HOSPITAL_TRAIN.csv\"\n",
    "    df = pd.read_csv(data_path)\n",
    "    cleaned_data = data_preprocessing(df)\n",
    "    y, X = split_feature_label(cleaned_data)\n",
    "    X = standardize(X)\n",
    "    train_model(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fabcd7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj Reddy Gurram\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\Manoj Reddy Gurram\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6867256637168142\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dropout\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def data_preprocessing(df):\n",
    "    \n",
    "    col_to_keep = ['death', 'age', 'blood', 'reflex', 'bloodchem1', 'bloodchem2', 'psych1', 'glucose']\n",
    "    df = df[col_to_keep]\n",
    "\n",
    "    df.replace('', 0, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "    \n",
    "def split_feature_label(df):\n",
    "    y = df['death']\n",
    "    X = df.drop(columns=['death'])\n",
    "    return y, X\n",
    "    # print(X)\n",
    "    # print(y)\n",
    "\n",
    "    # death_0 = y.tolist().count(0)\n",
    "    # death_1 = y.tolist().count(1)\n",
    "    # percent_death_0 = 100 * death_0 / (death_0 + death_1)\n",
    "    # percent_death_1 = 100 * death_1 / (death_0 + death_1)\n",
    "    # print(f'Survived: {death_0}, or {percent_death_0:.2f}%')\n",
    "    # print(f'Died: {death_1}, or {percent_death_1:.2f}%')\n",
    "\n",
    "def standardize(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_numeric = scaler.fit_transform(X.select_dtypes(include=['float64']))\n",
    "    X[X.select_dtypes(include=['float64']).columns] = X_numeric\n",
    "    return X\n",
    "\n",
    "def train_model(X, y):\n",
    "    # Split data into training and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Define the neural network model\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    history = rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred_proba = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "    # Calculate the log loss\n",
    "    test_loss = log_loss(y_test, y_pred_proba)\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "    # Optionally, you can plot training history to visualize model performance\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "#     plt.plot(history.history['accuracy'], label='accuracy')\n",
    "#     plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"C:/Users/Manoj Reddy Gurram/Desktop/TDHospital/TDHospital/TD_HOSPITAL_TRAIN.csv\"\n",
    "    df = pd.read_csv(data_path)\n",
    "    cleaned_data = data_preprocessing(df)\n",
    "    y, X = split_feature_label(cleaned_data)\n",
    "    X = standardize(X)\n",
    "    train_model(X, y)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
