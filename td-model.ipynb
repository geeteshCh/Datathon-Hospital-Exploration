{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d5132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6729c1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7058, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeknown</th>\n",
       "      <th>cost</th>\n",
       "      <th>reflex</th>\n",
       "      <th>sex</th>\n",
       "      <th>blood</th>\n",
       "      <th>bloodchem1</th>\n",
       "      <th>bloodchem2</th>\n",
       "      <th>temperature</th>\n",
       "      <th>race</th>\n",
       "      <th>heart</th>\n",
       "      <th>...</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>income</th>\n",
       "      <th>extraprimary</th>\n",
       "      <th>bloodchem6</th>\n",
       "      <th>education</th>\n",
       "      <th>psych5</th>\n",
       "      <th>psych6</th>\n",
       "      <th>information</th>\n",
       "      <th>cancer</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3008.38867</td>\n",
       "      <td>11.228005</td>\n",
       "      <td>male</td>\n",
       "      <td>20.699219</td>\n",
       "      <td>2.199707</td>\n",
       "      <td>1.299805</td>\n",
       "      <td>35.59375</td>\n",
       "      <td>white</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>167.5000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>467.0</td>\n",
       "      <td>23585.89060</td>\n",
       "      <td>9.714861</td>\n",
       "      <td>M</td>\n",
       "      <td>9.398438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>white</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&gt;$50k</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>480.0000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>metastatic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>533.0</td>\n",
       "      <td>4046.45898</td>\n",
       "      <td>11.353296</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.296875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.599854</td>\n",
       "      <td>38.19531</td>\n",
       "      <td>white</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>177.1250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.269058</td>\n",
       "      <td>female</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>37.59375</td>\n",
       "      <td>white</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.839</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1605.0</td>\n",
       "      <td>6457.70703</td>\n",
       "      <td>8.655387</td>\n",
       "      <td>female</td>\n",
       "      <td>15.099609</td>\n",
       "      <td>4.399414</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>35.69531</td>\n",
       "      <td>white</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>233.3125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timeknown         cost     reflex     sex      blood  bloodchem1  \\\n",
       "0        4.0   3008.38867  11.228005    male  20.699219    2.199707   \n",
       "1      467.0  23585.89060   9.714861       M   9.398438         NaN   \n",
       "2      533.0   4046.45898  11.353296    Male  19.296875         NaN   \n",
       "3       68.0          NaN   9.269058  female   7.500000    2.500000   \n",
       "4     1605.0   6457.70703   8.655387  female  15.099609    4.399414   \n",
       "\n",
       "   bloodchem2  temperature   race  heart  ...  diabetes      income  \\\n",
       "0    1.299805     35.59375  white  103.0  ...       0.0    $11-$25k   \n",
       "1    0.699951     39.00000  white   50.0  ...       0.0       >$50k   \n",
       "2    1.599854     38.19531  white   50.0  ...       1.0  under $11k   \n",
       "3    0.599976     37.59375  white   80.0  ...       0.0    $11-$25k   \n",
       "4    0.699951     35.69531  white  114.0  ...       0.0  under $11k   \n",
       "\n",
       "         extraprimary  bloodchem6  education  psych5  psych6  information  \\\n",
       "0  COPD/CHF/Cirrhosis    167.5000       20.0    30.0   2.000          0.0   \n",
       "1              Cancer    480.0000       16.0    11.5   1.000         10.0   \n",
       "2            ARF/MOSF    177.1250        5.0    18.0   0.000          5.0   \n",
       "3  COPD/CHF/Cirrhosis         NaN       12.0     7.0   1.839         12.0   \n",
       "4  COPD/CHF/Cirrhosis    233.3125        2.0     7.0   6.000         12.0   \n",
       "\n",
       "       cancer  death  \n",
       "0          no    1.0  \n",
       "1  metastatic    1.0  \n",
       "2         yes    0.0  \n",
       "3          no    1.0  \n",
       "4          no    0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./TD_HOSPITAL_TRAIN.csv\")\n",
    "print(df1.shape)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fba4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df1['death']\n",
    "# print(y.shape)\n",
    "# print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34216546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeknown</th>\n",
       "      <th>cost</th>\n",
       "      <th>reflex</th>\n",
       "      <th>sex</th>\n",
       "      <th>blood</th>\n",
       "      <th>bloodchem1</th>\n",
       "      <th>bloodchem2</th>\n",
       "      <th>temperature</th>\n",
       "      <th>race</th>\n",
       "      <th>heart</th>\n",
       "      <th>...</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>income</th>\n",
       "      <th>extraprimary</th>\n",
       "      <th>bloodchem6</th>\n",
       "      <th>education</th>\n",
       "      <th>psych5</th>\n",
       "      <th>psych6</th>\n",
       "      <th>information</th>\n",
       "      <th>cancer</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3008.38867</td>\n",
       "      <td>11.228005</td>\n",
       "      <td>male</td>\n",
       "      <td>20.699219</td>\n",
       "      <td>2.199707</td>\n",
       "      <td>1.299805</td>\n",
       "      <td>35.59375</td>\n",
       "      <td>white</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>167.5000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>467.0</td>\n",
       "      <td>23585.89060</td>\n",
       "      <td>9.714861</td>\n",
       "      <td>M</td>\n",
       "      <td>9.398438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>white</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&gt;$50k</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>480.0000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>metastatic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>533.0</td>\n",
       "      <td>4046.45898</td>\n",
       "      <td>11.353296</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.296875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.599854</td>\n",
       "      <td>38.19531</td>\n",
       "      <td>white</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>177.1250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.269058</td>\n",
       "      <td>female</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>37.59375</td>\n",
       "      <td>white</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.839</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1605.0</td>\n",
       "      <td>6457.70703</td>\n",
       "      <td>8.655387</td>\n",
       "      <td>female</td>\n",
       "      <td>15.099609</td>\n",
       "      <td>4.399414</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>35.69531</td>\n",
       "      <td>white</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>233.3125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timeknown         cost     reflex     sex      blood  bloodchem1  \\\n",
       "0        4.0   3008.38867  11.228005    male  20.699219    2.199707   \n",
       "1      467.0  23585.89060   9.714861       M   9.398438         NaN   \n",
       "2      533.0   4046.45898  11.353296    Male  19.296875         NaN   \n",
       "3       68.0          NaN   9.269058  female   7.500000    2.500000   \n",
       "4     1605.0   6457.70703   8.655387  female  15.099609    4.399414   \n",
       "\n",
       "   bloodchem2  temperature   race  heart  ...  diabetes      income  \\\n",
       "0    1.299805     35.59375  white  103.0  ...       0.0    $11-$25k   \n",
       "1    0.699951     39.00000  white   50.0  ...       0.0       >$50k   \n",
       "2    1.599854     38.19531  white   50.0  ...       1.0  under $11k   \n",
       "3    0.599976     37.59375  white   80.0  ...       0.0    $11-$25k   \n",
       "4    0.699951     35.69531  white  114.0  ...       0.0  under $11k   \n",
       "\n",
       "         extraprimary  bloodchem6  education  psych5  psych6  information  \\\n",
       "0  COPD/CHF/Cirrhosis    167.5000       20.0    30.0   2.000          0.0   \n",
       "1              Cancer    480.0000       16.0    11.5   1.000         10.0   \n",
       "2            ARF/MOSF    177.1250        5.0    18.0   0.000          5.0   \n",
       "3  COPD/CHF/Cirrhosis         NaN       12.0     7.0   1.839         12.0   \n",
       "4  COPD/CHF/Cirrhosis    233.3125        2.0     7.0   6.000         12.0   \n",
       "\n",
       "       cancer  death  \n",
       "0          no    1.0  \n",
       "1  metastatic    1.0  \n",
       "2         yes    0.0  \n",
       "3          no    1.0  \n",
       "4          no    0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83885d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, data: pd.DataFrame) -> None:\n",
    "        # drop columns\n",
    "        self.data = data.copy()\n",
    "\n",
    "        # drop columns\n",
    "        self.data = self.data.drop('pdeath',axis=1)\n",
    "        self.data = self.data.drop('psych4',axis=1)\n",
    "        self.data = self.data.drop('glucose',axis=1)\n",
    "        self.data = self.data.drop('bloodchem4', axis=1)\n",
    "        self.data = self.data.drop('urine',axis =1)\n",
    "        self.data = self.data.drop('income',axis =1)\n",
    "\n",
    "        # clean data\n",
    "        self.data = self.data.apply(self.clean, axis=1)\n",
    "\n",
    "        # replace missing data\n",
    "        self.clean_fill_mean('psych2')\n",
    "        self.clean_fill_mean('bloodchem3')\n",
    "        self.replace_missing_with_knn('totalcost', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('confidence', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('bloodchem1', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('bloodchem2', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('blood', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('cost', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('sleep', n_neighbors=10)\n",
    "        self.replace_missing_with_knn('bloodchem5', n_neighbors=10)\n",
    "        self.replace_missing_with_mode('disability')\n",
    "        self.replace_missing_with_knn('administratorcost')\n",
    "        self.replace_missing_with_knn('diabetes')\n",
    "        self.replace_missing_with_knn('bloodchem6')\n",
    "        self.replace_missing_with_knn('education')\n",
    "        self.replace_missing_with_knn('psych5')\n",
    "        self.replace_missing_with_knn('psych6')\n",
    "        self.replace_missing_with_knn('information')\n",
    "\n",
    "\n",
    "        # one hot encode the data\n",
    "        self.one_hot_encode_feature('cancer')\n",
    "        self.one_hot_encode_feature('extraprimary')\n",
    "        self.one_hot_encode_feature('dnr')\n",
    "        self.one_hot_encode_feature('primary')\n",
    "        self.one_hot_encode_feature('disability')\n",
    "\n",
    "\n",
    "    \n",
    "    def clean(self, row):\n",
    "        row.sex = self.cleanSex(row.sex)\n",
    "        row.race = self.cleanRace(row.race)\n",
    "        row.cost = self.cleanCost(row.cost)\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    # preproc for cost\n",
    "    def cleanCost(self, val: float):\n",
    "        if pd.isna(val) or val < 0:\n",
    "            return np.nan\n",
    "        \n",
    "        return val\n",
    "\n",
    "\n",
    "    # preproc logic for cleaning sex\n",
    "    def cleanSex(self, val):\n",
    "        val = val.lower()\n",
    "        # 1: male\n",
    "        if val in ['male', 'm', '1']:\n",
    "            return 1\n",
    "        # 0: female\n",
    "        return 0\n",
    "\n",
    "    # preproc logic for race\n",
    "    def cleanRace(self, val):\n",
    "        # unique values: ['white', 'black', 'hispanic', 'other', nan, 'asian']\n",
    "        WHITE = 0\n",
    "        BLACK = 1\n",
    "        HISPANIC = 2\n",
    "        OTHER = 3\n",
    "        ASIAN = 4\n",
    "\n",
    "        if(pd.isna(val)):\n",
    "            return OTHER\n",
    "        \n",
    "        val = val.lower()\n",
    "\n",
    "        if val == 'white':\n",
    "            return WHITE\n",
    "        elif val == 'black':\n",
    "            return BLACK\n",
    "        elif val == 'hispanic':\n",
    "            return HISPANIC\n",
    "        elif val == 'other':\n",
    "            return OTHER\n",
    "        elif val == 'asian':\n",
    "            return ASIAN\n",
    "\n",
    "\n",
    "        print('not possible')\n",
    "        return -1\n",
    "    \n",
    "\n",
    "    def one_hot_encode_feature(self, feature_name):\n",
    "        \"\"\"\n",
    "        One-hot encodes a specified feature from a DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        - dataframe: The input DataFrame.\n",
    "        - feature_name: The name of the feature to be one-hot encoded.\n",
    "\n",
    "        Returns:\n",
    "        - one_hot_df: A DataFrame containing the one-hot encoded feature.\n",
    "        \"\"\"\n",
    "\n",
    "        # Select the specified feature from the DataFrame\n",
    "        feature_to_encode = self.data[feature_name]\n",
    "\n",
    "        # Reshape the feature to have a 2D shape, required by OneHotEncoder\n",
    "        feature_to_encode = feature_to_encode.values.reshape(-1, 1)\n",
    "\n",
    "        # Create an instance of the OneHotEncoder\n",
    "        encoder = OneHotEncoder(sparse=False)  # You can set sparse=True if you want a sparse matrix\n",
    "\n",
    "        # Fit the encoder to the feature data\n",
    "        encoder.fit(feature_to_encode)\n",
    "\n",
    "        # Transform the feature data to one-hot encoded format\n",
    "        one_hot_encoded = encoder.transform(feature_to_encode)\n",
    "\n",
    "        # Convert the one-hot encoded data to a DataFrame for better visualization\n",
    "        one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out([feature_name]))\n",
    "        \n",
    "        \n",
    "        new_dataframe = self.data.drop(columns=[feature_name])  # Remove the target column\n",
    "        new_dataframe[one_hot_df.columns] = one_hot_df  # Add the source columns to the target DataFrame\n",
    "        \n",
    "        self.data = new_dataframe\n",
    "\n",
    "    # for glucose, psych2, \n",
    "    def clean_fill_mean(self, feature):\n",
    "        mean_value = self.data[feature].mean()\n",
    "        self.data[feature].fillna(mean_value, inplace=True)\n",
    "\n",
    "\n",
    "    # replacing the outliers after replacing missing values\n",
    "    def replace_outliers_with_mean(self, column_name, threshold=1.5):\n",
    "        # Calculate lower and upper bounds for outliers\n",
    "        Q1 = self.data[column_name].quantile(0.25)\n",
    "        Q3 = self.data[column_name].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "        # Identify outliers in the specified column\n",
    "        outliers = self.data[(self.data[column_name] < lower_bound) | (self.data[column_name] > upper_bound)]\n",
    "\n",
    "        # Replace outliers with the mean of the column\n",
    "        non_outliers_mean = self.data[([column_name] >= lower_bound) & (self.data[column_name] <= upper_bound)][column_name].mean()\n",
    "        self.data.loc[outliers.index, column_name] = non_outliers_mean\n",
    "\n",
    "\n",
    "    #replacing missing values with knn imputer\n",
    "    # for totalcost\n",
    "    def replace_missing_with_knn(self, column_name, n_neighbors=5):\n",
    "        # Create a copy of the DataFrame to avoid modifying the original data\n",
    "        df_imputed = self.data.copy()    \n",
    "        # Extract the column with missing values for imputation\n",
    "        column_to_impute = df_imputed[[column_name]]   \n",
    "        # Initialize KNNImputer with the desired number of neighbors\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)   \n",
    "        # Perform KNN imputation on the specified column\n",
    "        column_imputed = imputer.fit_transform(column_to_impute)   \n",
    "        # Replace the missing values in the original DataFrame with imputed values\n",
    "        df_imputed[column_name] = column_imputed\n",
    "        \n",
    "        self.data = df_imputed\n",
    "\n",
    "    \n",
    "    def replace_missing_with_mode(self, categorical_feature):\n",
    "        \"\"\"\n",
    "        Fill missing values in a categorical feature with the most frequent category.\n",
    "\n",
    "        Parameters:\n",
    "        - df: DataFrame containing the data.\n",
    "        - categorical_feature: Name of the categorical feature/column with missing values.\n",
    "\n",
    "        Returns:\n",
    "        - Updated DataFrame with missing values filled in the specified feature.\n",
    "        \"\"\"\n",
    "        # Find the most frequent category in the specified feature\n",
    "        most_frequent_category = self.data[categorical_feature].mode()[0]\n",
    "        \n",
    "        # Fill missing values in the specified feature with the most frequent category\n",
    "        self.data[categorical_feature].fillna(most_frequent_category, inplace=True)\n",
    "        \n",
    "    # Example Usage:\n",
    "    # Assuming 'df' is your DataFrame and 'categorical_column' is the name of the categorical feature with missing values\n",
    "    # df = fill_missing_categorical(df, 'categorical_column')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddba56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e91233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Geetesh/anaconda3/envs/work/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeknown</th>\n",
       "      <th>cost</th>\n",
       "      <th>reflex</th>\n",
       "      <th>sex</th>\n",
       "      <th>blood</th>\n",
       "      <th>bloodchem1</th>\n",
       "      <th>bloodchem2</th>\n",
       "      <th>temperature</th>\n",
       "      <th>race</th>\n",
       "      <th>heart</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_Cirrhosis</th>\n",
       "      <th>primary_Colon Cancer</th>\n",
       "      <th>primary_Coma</th>\n",
       "      <th>primary_Lung Cancer</th>\n",
       "      <th>primary_MOSF w/Malig</th>\n",
       "      <th>disability_&lt;2 mo. follow-up</th>\n",
       "      <th>disability_Coma or Intub</th>\n",
       "      <th>disability_SIP&gt;=30</th>\n",
       "      <th>disability_adl&gt;=4 (&gt;=5 if sur)</th>\n",
       "      <th>disability_no(M2 and SIP pres)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3008.388670</td>\n",
       "      <td>11.228005</td>\n",
       "      <td>1</td>\n",
       "      <td>20.699219</td>\n",
       "      <td>2.199707</td>\n",
       "      <td>1.299805</td>\n",
       "      <td>35.59375</td>\n",
       "      <td>0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>467.0</td>\n",
       "      <td>23585.890600</td>\n",
       "      <td>9.714861</td>\n",
       "      <td>1</td>\n",
       "      <td>9.398438</td>\n",
       "      <td>2.946952</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>533.0</td>\n",
       "      <td>4046.458980</td>\n",
       "      <td>11.353296</td>\n",
       "      <td>1</td>\n",
       "      <td>19.296875</td>\n",
       "      <td>2.946952</td>\n",
       "      <td>1.599854</td>\n",
       "      <td>38.19531</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>28703.389688</td>\n",
       "      <td>9.269058</td>\n",
       "      <td>0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>37.59375</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1605.0</td>\n",
       "      <td>6457.707030</td>\n",
       "      <td>8.655387</td>\n",
       "      <td>0</td>\n",
       "      <td>15.099609</td>\n",
       "      <td>4.399414</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>35.69531</td>\n",
       "      <td>0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timeknown          cost     reflex  sex      blood  bloodchem1  bloodchem2  \\\n",
       "0        4.0   3008.388670  11.228005    1  20.699219    2.199707    1.299805   \n",
       "1      467.0  23585.890600   9.714861    1   9.398438    2.946952    0.699951   \n",
       "2      533.0   4046.458980  11.353296    1  19.296875    2.946952    1.599854   \n",
       "3       68.0  28703.389688   9.269058    0   7.500000    2.500000    0.599976   \n",
       "4     1605.0   6457.707030   8.655387    0  15.099609    4.399414    0.699951   \n",
       "\n",
       "   temperature  race  heart  ...  primary_Cirrhosis  primary_Colon Cancer  \\\n",
       "0     35.59375     0  103.0  ...                1.0                   0.0   \n",
       "1     39.00000     0   50.0  ...                0.0                   1.0   \n",
       "2     38.19531     0   50.0  ...                0.0                   0.0   \n",
       "3     37.59375     0   80.0  ...                1.0                   0.0   \n",
       "4     35.69531     0  114.0  ...                0.0                   0.0   \n",
       "\n",
       "   primary_Coma  primary_Lung Cancer  primary_MOSF w/Malig  \\\n",
       "0           0.0                  0.0                   0.0   \n",
       "1           0.0                  0.0                   0.0   \n",
       "2           0.0                  0.0                   0.0   \n",
       "3           0.0                  0.0                   0.0   \n",
       "4           0.0                  0.0                   0.0   \n",
       "\n",
       "   disability_<2 mo. follow-up  disability_Coma or Intub  disability_SIP>=30  \\\n",
       "0                          1.0                       0.0                 0.0   \n",
       "1                          0.0                       0.0                 0.0   \n",
       "2                          0.0                       0.0                 0.0   \n",
       "3                          0.0                       0.0                 0.0   \n",
       "4                          0.0                       0.0                 0.0   \n",
       "\n",
       "   disability_adl>=4 (>=5 if sur)  disability_no(M2 and SIP pres)  \n",
       "0                             0.0                             0.0  \n",
       "1                             0.0                             1.0  \n",
       "2                             0.0                             1.0  \n",
       "3                             0.0                             1.0  \n",
       "4                             0.0                             1.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = Dataset(df1).data\n",
    "cleaned_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c361956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeknown</th>\n",
       "      <th>cost</th>\n",
       "      <th>reflex</th>\n",
       "      <th>sex</th>\n",
       "      <th>blood</th>\n",
       "      <th>bloodchem1</th>\n",
       "      <th>bloodchem2</th>\n",
       "      <th>temperature</th>\n",
       "      <th>race</th>\n",
       "      <th>heart</th>\n",
       "      <th>...</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>income</th>\n",
       "      <th>extraprimary</th>\n",
       "      <th>bloodchem6</th>\n",
       "      <th>education</th>\n",
       "      <th>psych5</th>\n",
       "      <th>psych6</th>\n",
       "      <th>information</th>\n",
       "      <th>cancer</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3008.38867</td>\n",
       "      <td>11.228005</td>\n",
       "      <td>male</td>\n",
       "      <td>20.699219</td>\n",
       "      <td>2.199707</td>\n",
       "      <td>1.299805</td>\n",
       "      <td>35.59375</td>\n",
       "      <td>white</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>167.5000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>467.0</td>\n",
       "      <td>23585.89060</td>\n",
       "      <td>9.714861</td>\n",
       "      <td>M</td>\n",
       "      <td>9.398438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>white</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&gt;$50k</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>480.0000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>metastatic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>533.0</td>\n",
       "      <td>4046.45898</td>\n",
       "      <td>11.353296</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.296875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.599854</td>\n",
       "      <td>38.19531</td>\n",
       "      <td>white</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>ARF/MOSF</td>\n",
       "      <td>177.1250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.269058</td>\n",
       "      <td>female</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>37.59375</td>\n",
       "      <td>white</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.839</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1605.0</td>\n",
       "      <td>6457.70703</td>\n",
       "      <td>8.655387</td>\n",
       "      <td>female</td>\n",
       "      <td>15.099609</td>\n",
       "      <td>4.399414</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>35.69531</td>\n",
       "      <td>white</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>under $11k</td>\n",
       "      <td>COPD/CHF/Cirrhosis</td>\n",
       "      <td>233.3125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timeknown         cost     reflex     sex      blood  bloodchem1  \\\n",
       "0        4.0   3008.38867  11.228005    male  20.699219    2.199707   \n",
       "1      467.0  23585.89060   9.714861       M   9.398438         NaN   \n",
       "2      533.0   4046.45898  11.353296    Male  19.296875         NaN   \n",
       "3       68.0          NaN   9.269058  female   7.500000    2.500000   \n",
       "4     1605.0   6457.70703   8.655387  female  15.099609    4.399414   \n",
       "\n",
       "   bloodchem2  temperature   race  heart  ...  diabetes      income  \\\n",
       "0    1.299805     35.59375  white  103.0  ...       0.0    $11-$25k   \n",
       "1    0.699951     39.00000  white   50.0  ...       0.0       >$50k   \n",
       "2    1.599854     38.19531  white   50.0  ...       1.0  under $11k   \n",
       "3    0.599976     37.59375  white   80.0  ...       0.0    $11-$25k   \n",
       "4    0.699951     35.69531  white  114.0  ...       0.0  under $11k   \n",
       "\n",
       "         extraprimary  bloodchem6  education  psych5  psych6  information  \\\n",
       "0  COPD/CHF/Cirrhosis    167.5000       20.0    30.0   2.000          0.0   \n",
       "1              Cancer    480.0000       16.0    11.5   1.000         10.0   \n",
       "2            ARF/MOSF    177.1250        5.0    18.0   0.000          5.0   \n",
       "3  COPD/CHF/Cirrhosis         NaN       12.0     7.0   1.839         12.0   \n",
       "4  COPD/CHF/Cirrhosis    233.3125        2.0     7.0   6.000         12.0   \n",
       "\n",
       "       cancer  death  \n",
       "0          no    1.0  \n",
       "1  metastatic    1.0  \n",
       "2         yes    0.0  \n",
       "3          no    1.0  \n",
       "4          no    0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc469a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e13bb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc62e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_feature_label(df):\n",
    "    y = df['death']\n",
    "    X = df.drop(columns=['death'])\n",
    "    return y, X\n",
    "    # print(X)\n",
    "    # print(y)\n",
    "\n",
    "    # death_0 = y.tolist().count(0)\n",
    "    # death_1 = y.tolist().count(1)\n",
    "    # percent_death_0 = 100 * death_0 / (death_0 + death_1)\n",
    "    # percent_death_1 = 100 * death_1 / (death_0 + death_1)\n",
    "    # print(f'Survived: {death_0}, or {percent_death_0:.2f}%')\n",
    "    # print(f'Died: {death_1}, or {percent_death_1:.2f}%')\n",
    "\n",
    "def standardize(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_numeric = scaler.fit_transform(X.select_dtypes(include=['float64']))\n",
    "    X[X.select_dtypes(include=['float64']).columns] = X_numeric\n",
    "    return X\n",
    "\n",
    "def train_model(X, y):\n",
    "    # Split data into training and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=.3, random_state=42)\n",
    "\n",
    "    # Define the neural network model\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train.shape[1],)),  # Input layer\n",
    "        layers.Dense(128, activation='relu'),     # Hidden layer with 128 neurons and ReLU activation\n",
    "        layers.Dense(64, activation='relu'),      # Another hidden layer with 64 neurons and ReLU activation\n",
    "        layers.Dense(1, activation='sigmoid')     # Output layer with sigmoid activation for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    \n",
    "    model.save('example.h5')\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "    # Optionally, you can plot training history to visualize model performance\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7b880b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "177/177 [==============================] - 0s 821us/step - loss: 0.3788 - accuracy: 0.8181 - val_loss: 0.3669 - val_accuracy: 0.8188\n",
      "Epoch 2/50\n",
      "177/177 [==============================] - 0s 571us/step - loss: 0.3051 - accuracy: 0.8643 - val_loss: 0.3493 - val_accuracy: 0.8340\n",
      "Epoch 3/50\n",
      "177/177 [==============================] - 0s 567us/step - loss: 0.2779 - accuracy: 0.8742 - val_loss: 0.3310 - val_accuracy: 0.8401\n",
      "Epoch 4/50\n",
      "177/177 [==============================] - 0s 553us/step - loss: 0.2543 - accuracy: 0.8870 - val_loss: 0.3451 - val_accuracy: 0.8310\n",
      "Epoch 5/50\n",
      "177/177 [==============================] - 0s 568us/step - loss: 0.2347 - accuracy: 0.8957 - val_loss: 0.3236 - val_accuracy: 0.8532\n",
      "Epoch 6/50\n",
      "177/177 [==============================] - 0s 559us/step - loss: 0.2227 - accuracy: 0.9051 - val_loss: 0.3242 - val_accuracy: 0.8451\n",
      "Epoch 7/50\n",
      "177/177 [==============================] - 0s 563us/step - loss: 0.2049 - accuracy: 0.9125 - val_loss: 0.3143 - val_accuracy: 0.8512\n",
      "Epoch 8/50\n",
      "177/177 [==============================] - 0s 591us/step - loss: 0.1920 - accuracy: 0.9221 - val_loss: 0.3344 - val_accuracy: 0.8451\n",
      "Epoch 9/50\n",
      "177/177 [==============================] - 0s 589us/step - loss: 0.1761 - accuracy: 0.9276 - val_loss: 0.3287 - val_accuracy: 0.8451\n",
      "Epoch 10/50\n",
      "177/177 [==============================] - 0s 574us/step - loss: 0.1676 - accuracy: 0.9315 - val_loss: 0.3347 - val_accuracy: 0.8370\n",
      "Epoch 11/50\n",
      "177/177 [==============================] - 0s 565us/step - loss: 0.1548 - accuracy: 0.9362 - val_loss: 0.3312 - val_accuracy: 0.8472\n",
      "Epoch 12/50\n",
      "177/177 [==============================] - 0s 559us/step - loss: 0.1427 - accuracy: 0.9439 - val_loss: 0.3431 - val_accuracy: 0.8462\n",
      "Epoch 13/50\n",
      "177/177 [==============================] - 0s 563us/step - loss: 0.1294 - accuracy: 0.9485 - val_loss: 0.3796 - val_accuracy: 0.8401\n",
      "Epoch 14/50\n",
      "177/177 [==============================] - 0s 573us/step - loss: 0.1191 - accuracy: 0.9532 - val_loss: 0.3686 - val_accuracy: 0.8411\n",
      "Epoch 15/50\n",
      "177/177 [==============================] - 0s 560us/step - loss: 0.1093 - accuracy: 0.9596 - val_loss: 0.3856 - val_accuracy: 0.8441\n",
      "Epoch 16/50\n",
      "177/177 [==============================] - 0s 565us/step - loss: 0.1026 - accuracy: 0.9633 - val_loss: 0.3942 - val_accuracy: 0.8462\n",
      "Epoch 17/50\n",
      "177/177 [==============================] - 0s 586us/step - loss: 0.0901 - accuracy: 0.9683 - val_loss: 0.4012 - val_accuracy: 0.8411\n",
      "Epoch 18/50\n",
      "177/177 [==============================] - 0s 568us/step - loss: 0.0820 - accuracy: 0.9738 - val_loss: 0.4312 - val_accuracy: 0.8411\n",
      "Epoch 19/50\n",
      "177/177 [==============================] - 0s 574us/step - loss: 0.0742 - accuracy: 0.9748 - val_loss: 0.4550 - val_accuracy: 0.8381\n",
      "Epoch 20/50\n",
      "177/177 [==============================] - 0s 574us/step - loss: 0.0665 - accuracy: 0.9789 - val_loss: 0.4846 - val_accuracy: 0.8330\n",
      "Epoch 21/50\n",
      "177/177 [==============================] - 0s 585us/step - loss: 0.0618 - accuracy: 0.9795 - val_loss: 0.4958 - val_accuracy: 0.8350\n",
      "Epoch 22/50\n",
      "177/177 [==============================] - 0s 570us/step - loss: 0.0560 - accuracy: 0.9823 - val_loss: 0.5103 - val_accuracy: 0.8451\n",
      "Epoch 23/50\n",
      "177/177 [==============================] - 0s 579us/step - loss: 0.0485 - accuracy: 0.9867 - val_loss: 0.5719 - val_accuracy: 0.8300\n",
      "Epoch 24/50\n",
      "177/177 [==============================] - 0s 572us/step - loss: 0.0433 - accuracy: 0.9881 - val_loss: 0.5415 - val_accuracy: 0.8431\n",
      "Epoch 25/50\n",
      "177/177 [==============================] - 0s 570us/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 0.5847 - val_accuracy: 0.8350\n",
      "Epoch 26/50\n",
      "177/177 [==============================] - 0s 567us/step - loss: 0.0369 - accuracy: 0.9881 - val_loss: 0.6212 - val_accuracy: 0.8360\n",
      "Epoch 27/50\n",
      "177/177 [==============================] - 0s 572us/step - loss: 0.0304 - accuracy: 0.9920 - val_loss: 0.6458 - val_accuracy: 0.8370\n",
      "Epoch 28/50\n",
      "177/177 [==============================] - 0s 573us/step - loss: 0.0256 - accuracy: 0.9954 - val_loss: 0.6669 - val_accuracy: 0.8330\n",
      "Epoch 29/50\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.0204 - accuracy: 0.9975 - val_loss: 0.7053 - val_accuracy: 0.8462\n",
      "Epoch 30/50\n",
      "177/177 [==============================] - 0s 562us/step - loss: 0.0188 - accuracy: 0.9977 - val_loss: 0.7478 - val_accuracy: 0.8421\n",
      "Epoch 31/50\n",
      "177/177 [==============================] - 0s 557us/step - loss: 0.0193 - accuracy: 0.9963 - val_loss: 0.7765 - val_accuracy: 0.8320\n",
      "Epoch 32/50\n",
      "177/177 [==============================] - 0s 572us/step - loss: 0.0423 - accuracy: 0.9876 - val_loss: 0.7423 - val_accuracy: 0.8370\n",
      "Epoch 33/50\n",
      "177/177 [==============================] - 0s 574us/step - loss: 0.0384 - accuracy: 0.9881 - val_loss: 0.7918 - val_accuracy: 0.8370\n",
      "Epoch 34/50\n",
      "177/177 [==============================] - 0s 580us/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.8184 - val_accuracy: 0.8340\n",
      "Epoch 35/50\n",
      "177/177 [==============================] - 0s 580us/step - loss: 0.0144 - accuracy: 0.9988 - val_loss: 0.8270 - val_accuracy: 0.8360\n",
      "Epoch 36/50\n",
      "177/177 [==============================] - 0s 569us/step - loss: 0.0108 - accuracy: 0.9991 - val_loss: 0.8574 - val_accuracy: 0.8381\n",
      "Epoch 37/50\n",
      "177/177 [==============================] - 0s 559us/step - loss: 0.0080 - accuracy: 0.9993 - val_loss: 0.8879 - val_accuracy: 0.8320\n",
      "Epoch 38/50\n",
      "177/177 [==============================] - 0s 562us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.9124 - val_accuracy: 0.8391\n",
      "Epoch 39/50\n",
      "177/177 [==============================] - 0s 555us/step - loss: 0.0062 - accuracy: 0.9998 - val_loss: 0.9726 - val_accuracy: 0.8431\n",
      "Epoch 40/50\n",
      "177/177 [==============================] - 0s 562us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.8360\n",
      "Epoch 41/50\n",
      "177/177 [==============================] - 0s 553us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.8370\n",
      "Epoch 42/50\n",
      "177/177 [==============================] - 0s 567us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.8381\n",
      "Epoch 43/50\n",
      "177/177 [==============================] - 0s 562us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0207 - val_accuracy: 0.8381\n",
      "Epoch 44/50\n",
      "177/177 [==============================] - 0s 571us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.8411\n",
      "Epoch 45/50\n",
      "177/177 [==============================] - 0s 577us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0732 - val_accuracy: 0.8360\n",
      "Epoch 46/50\n",
      "177/177 [==============================] - 0s 564us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0936 - val_accuracy: 0.8360\n",
      "Epoch 47/50\n",
      "177/177 [==============================] - 0s 563us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1132 - val_accuracy: 0.8411\n",
      "Epoch 48/50\n",
      "177/177 [==============================] - 0s 576us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1311 - val_accuracy: 0.8401\n",
      "Epoch 49/50\n",
      "177/177 [==============================] - 0s 564us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1654 - val_accuracy: 0.8411\n",
      "Epoch 50/50\n",
      "177/177 [==============================] - 0s 582us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1859 - val_accuracy: 0.8401\n",
      "14/14 [==============================] - 0s 466us/step - loss: 0.7738 - accuracy: 0.8585\n",
      "Test accuracy: 0.8584905862808228\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y, X = split_feature_label(cleaned_data)\n",
    "X = standardize(X)\n",
    "train_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd5ff1",
   "metadata": {},
   "source": [
    "<h1>Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96fa01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 413us/step - loss: 0.7738 - accuracy: 0.8585\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8584905862808228\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=.3, random_state=42)\n",
    "\n",
    "model2 = load_model('example.h5')\n",
    "test_loss, test_accuracy = model2.evaluate(X_test, y_test)\n",
    "train_loss, train_accuracy = model2.evaluate(X_train, y_train)\n",
    "\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c63ed8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k9[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd221db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91039351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#         layers.Input(shape=(X_train.shape[1],)),  # Input layer\n",
    "#         layers.Dense(128, activation='relu'),     # Hidden layer with 128 neurons and ReLU activation\n",
    "#         layers.Dense(64, activation='relu'),      # Another hidden layer with 64 neurons and ReLU activation\n",
    "#         layers.Dense(1, activation='sigmoid')     # Output layer with sigmoid activation for binary classification\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c36d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, X = split_feature_label(cleaned_data)\n",
    "# X = standardize(X)\n",
    "# train_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37009d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from keras.layers import Dropout\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from tensorflow.keras import regularizers\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# def data_preprocessing(df):\n",
    "    \n",
    "#     col_to_keep = ['death', 'age', 'blood', 'reflex', 'bloodchem1', 'bloodchem2', 'psych1', 'glucose']\n",
    "#     df = df[col_to_keep]\n",
    "\n",
    "#     df.replace('', 0, inplace=True)\n",
    "#     df.fillna(0, inplace=True)\n",
    "#     return df\n",
    "    \n",
    "# def split_feature_label(df):\n",
    "#     y = df['death']\n",
    "#     X = df.drop(columns=['death'])\n",
    "#     return y, X\n",
    "#     # print(X)\n",
    "#     # print(y)\n",
    "\n",
    "#     # death_0 = y.tolist().count(0)\n",
    "#     # death_1 = y.tolist().count(1)\n",
    "#     # percent_death_0 = 100 * death_0 / (death_0 + death_1)\n",
    "#     # percent_death_1 = 100 * death_1 / (death_0 + death_1)\n",
    "#     # print(f'Survived: {death_0}, or {percent_death_0:.2f}%')\n",
    "#     # print(f'Died: {death_1}, or {percent_death_1:.2f}%')\n",
    "\n",
    "# def standardize(X):\n",
    "#     scaler = StandardScaler()\n",
    "#     X_numeric = scaler.fit_transform(X.select_dtypes(include=['float64']))\n",
    "#     X[X.select_dtypes(include=['float64']).columns] = X_numeric\n",
    "#     return X\n",
    "\n",
    "# def train_model(X, y):\n",
    "#     # Split data into training and validation\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "#     # Define the neural network model\n",
    "#     model = keras.Sequential([\n",
    "#         layers.Input(shape=(X_train.shape[1],)),  # Input layer\n",
    "#         layers.Dense(512, activation='relu',kernel_regularizer=regularizers.L1(0.01)), \n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(256, activation='relu',kernel_regularizer=regularizers.L1(0.01)),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(128, activation='relu',kernel_regularizer=regularizers.L1(0.01)),  # Hidden layer with 128 neurons and ReLU activation\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(64, activation='relu' ,kernel_regularizer=regularizers.L1(0.01)),      # Another hidden layer with 64 neurons and ReLU activation\n",
    "#         layers.Dense(1, activation='sigmoid')     # Output layer with sigmoid activation for binary classification\n",
    "#     ])\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     # Train the model\n",
    "#     history = Logistic_reg = LogisticRegression(random_state=42,max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "#     # Evaluate the model on the test set\n",
    "#     y_pred_proba = Logistic_reg.predict_proba(X_test)\n",
    "\n",
    "#     # Calculate the log loss\n",
    "#     test_loss = log_loss(y_test, y_pred_proba)\n",
    "#     y_pred = Logistic_reg.predict(X_test)\n",
    "\n",
    "#     # Calculate the accuracy\n",
    "#     test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "#     model.save('example.h5')\n",
    "    \n",
    "#     print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "#     # Optionally, you can plot training history to visualize model performance\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "# #     plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# #     plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# #     plt.xlabel('Epoch')\n",
    "# #     plt.ylabel('Accuracy')\n",
    "# #     plt.ylim([0, 1])\n",
    "# #     plt.legend(loc='lower right')\n",
    "# #     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     data_path = \"C:/Users/Manoj Reddy Gurram/Desktop/TDHospital/TDHospital/TD_HOSPITAL_TRAIN.csv\"\n",
    "#     df = pd.read_csv(data_path)\n",
    "#     cleaned_data = data_preprocessing(df)\n",
    "#     y, X = split_feature_label(cleaned_data)\n",
    "#     X = standardize(X)\n",
    "#     train_model(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fabcd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from keras.layers import Dropout\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from tensorflow.keras import regularizers\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# def data_preprocessing(df):\n",
    "    \n",
    "#     col_to_keep = ['death', 'age', 'blood', 'reflex', 'bloodchem1', 'bloodchem2', 'psych1', 'glucose']\n",
    "#     df = df[col_to_keep]\n",
    "\n",
    "#     df.replace('', 0, inplace=True)\n",
    "#     df.fillna(0, inplace=True)\n",
    "#     return df\n",
    "    \n",
    "# def split_feature_label(df):\n",
    "#     y = df['death']\n",
    "#     X = df.drop(columns=['death'])\n",
    "#     return y, X\n",
    "#     # print(X)\n",
    "#     # print(y)\n",
    "\n",
    "#     # death_0 = y.tolist().count(0)\n",
    "#     # death_1 = y.tolist().count(1)\n",
    "#     # percent_death_0 = 100 * death_0 / (death_0 + death_1)\n",
    "#     # percent_death_1 = 100 * death_1 / (death_0 + death_1)\n",
    "#     # print(f'Survived: {death_0}, or {percent_death_0:.2f}%')\n",
    "#     # print(f'Died: {death_1}, or {percent_death_1:.2f}%')\n",
    "\n",
    "# def standardize(X):\n",
    "#     scaler = StandardScaler()\n",
    "#     X_numeric = scaler.fit_transform(X.select_dtypes(include=['float64']))\n",
    "#     X[X.select_dtypes(include=['float64']).columns] = X_numeric\n",
    "#     return X\n",
    "\n",
    "# def train_model(X, y):\n",
    "#     # Split data into training and validation\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "#     # Define the neural network model\n",
    "#     rf_classifier = RandomForestClassifier()\n",
    "#     history = rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "#     # Evaluate the model on the test set\n",
    "#     y_pred_proba = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "#     # Calculate the log loss\n",
    "#     test_loss = log_loss(y_test, y_pred_proba)\n",
    "#     y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "#     # Calculate the accuracy\n",
    "#     test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "#     print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "#     # Optionally, you can plot training history to visualize model performance\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "# #     plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# #     plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# #     plt.xlabel('Epoch')\n",
    "# #     plt.ylabel('Accuracy')\n",
    "# #     plt.ylim([0, 1])\n",
    "# #     plt.legend(loc='lower right')\n",
    "# #     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     data_path = \"C:/Users/Manoj Reddy Gurram/Desktop/TDHospital/TDHospital/TD_HOSPITAL_TRAIN.csv\"\n",
    "#     df = pd.read_csv(data_path)\n",
    "#     cleaned_data = data_preprocessing(df)\n",
    "#     y, X = split_feature_label(cleaned_data)\n",
    "#     X = standardize(X)\n",
    "#     train_model(X, y)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
